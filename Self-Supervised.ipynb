{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fcab066-7638-4153-a7b9-184f4593d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33879378-cb7c-4471-bc4e-91c89b0aae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b295d03d-fb0e-47ea-8609-e0f1bba774c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d246b9d-6ee4-4982-bab4-f1cf7843b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04eeba37-994a-4332-9ca4-2f884c44e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLRDataTransform(object):\n",
    "    def __init__(self, size):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=size), #Randomly crop images\n",
    "            transforms.RandomHorizontalFlip(), #Randomly flip images horizontally\n",
    "            transforms.RandomApply([transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8), #Perform color distortion and grayscale conversion\n",
    "            transforms.RandomGrayscale(p=0.2), #Perform color distortion and grayscale conversion\n",
    "            transforms.GaussianBlur(kernel_size=int(0.1 * size)), #Apply Gaussian Blur\n",
    "            transforms.ToTensor(), #Convert image to Tensor and normalize\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #Convert image to Tensor and normalize\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf55dcc9-32ee-4ab3-9472-08470516cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image)\n",
    "            image2 = self.transform(image)\n",
    "            return image1, image2\n",
    "        return image, image\n",
    "\n",
    "# Use custom dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "trainset = SimCLRDataset(trainset, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a0d762-97a1-494f-ae92-92409a06ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "        # Remove the last fully connected layer\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e7225b-6eaa-44ff-a0a8-be2928bb718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=2048, hidden_dim=512, output_dim=128):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c98ffce-378e-4419-9262-ce4bb2cafe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, encoder, projection_head):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.projection_head = projection_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.projection_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c30be4b1-4b4e-4732-b1ab-2d1cf8ad41d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ResNetEncoder()\n",
    "projection_head = ProjectionHead()\n",
    "model = SimCLR(encoder, projection_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2aa186-9875-43dd-a4e5-042a9c882555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nt_xent_loss(features, temperature=0.5):\n",
    "#     \"\"\"\n",
    "#     计算NT-Xent Loss\n",
    "\n",
    "#     :param features: 特征向量，大小为 [2 * batch_size, feature_dim]\n",
    "#     :param temperature: 温度参数\n",
    "#     :return: 损失值\n",
    "#     \"\"\"\n",
    "#     device = features.device\n",
    "#     batch_size, _ = features.shape\n",
    "#     labels = torch.cat([torch.arange(batch_size // 2) for _ in range(2)], dim=0)\n",
    "#     labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float().to(device)\n",
    "\n",
    "#     features = F.normalize(features, dim=1)\n",
    "\n",
    "#     similarity_matrix = torch.matmul(features, features.T)\n",
    "\n",
    "#     # 排除对角线元素\n",
    "#     mask = torch.eye(labels.shape[0], dtype=torch.bool).to(device)\n",
    "#     labels = labels[~mask].view(labels.shape[0], -1)\n",
    "#     similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "#     # 使用交叉熵损失计算\n",
    "#     positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "#     negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "#     logits = torch.cat([positives, negatives], dim=1)\n",
    "#     labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)\n",
    "\n",
    "#     logits = logits / temperature\n",
    "#     return F.cross_entropy(logits, labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def NT_XEnt(interleaved_inputs, temperature=0.5):\n",
    "    length = interleaved_inputs.shape[0]\n",
    "    \n",
    "    xcs = F.cosine_similarity(interleaved_inputs[None,:,:], interleaved_inputs[:,None,:], dim=-1)\n",
    "    eye = torch.eye(length)\n",
    "    y = xcs.clone()\n",
    "    y[eye.bool()] = float(\"-inf\")\n",
    "    y = y / temperature\n",
    "    \n",
    "    target = torch.arange(length)\n",
    "    target[0::2] += 1\n",
    "    target[1::2] -= 1\n",
    "    \n",
    "    index = target.reshape(length, 1).long()\n",
    "    \n",
    "    ground_truth_labels = torch.zeros(8,8).long()\n",
    "    src = torch.ones(length, length).long()\n",
    "    ground_truth_labels = torch.scatter(ground_truth_labels, 1, index, src)\n",
    "    \n",
    "    return F.cross_entropy(y, target, reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d8dc8-c192-4ee0-8118-fc965517d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "batch_size = 256  # Adjust according to your GPU\n",
    "epochs = 100  # Adjust to your needs\n",
    "# Define learning rate and momentum\n",
    "learning_rate = 0.1  # According to the paper, the initial learning rate is set to 0.1, but you can adjust it according to the actual situation\n",
    "momentum = 0.9       # Momentum is usually set to 0.9\n",
    "\n",
    "# Instantiate the SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "print(\"optimizer\")\n",
    "# Assuming trainloader is your data loader\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    for batch in trainloader:\n",
    "        # Assume that the trainloader returns a pair of enhanced image sets\n",
    "        images1, images2 = batch\n",
    "\n",
    "        # Make sure images1 and images2 are both four-dimensional tensors\n",
    "        # Shape should be [batch_size, channels, height, width]\n",
    "\n",
    "        concatenated_images = torch.cat((images1, images2), dim=0)  # 在批次维度上合并\n",
    "\n",
    "        optimizer.zero_grad()  # 梯度归零\n",
    "\n",
    "        features = model(concatenated_images)  # 获取特征表示\n",
    "        loss = NT_XEnt(features)  # 计算NT-Xent Loss\n",
    "\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新权重\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(trainloader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'simclr_model.pth')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def49b8c-2dcd-4bb8-9ed3-2e3118e097a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
