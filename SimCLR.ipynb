{"cells":[{"cell_type":"markdown","metadata":{"id":"wA-QqLiYgzSc"},"source":[]},{"cell_type":"markdown","metadata":{"id":"_PypqqXnhqz4"},"source":["## Step 0: Set up the SimpleNN model\n","As you have practiced to implement simple neural networks in Homework 1, we just prepare the implementation for you."]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNDZdI-9hqz5","outputId":"767a85f6-985f-4512-fe8e-cd32b6b561de","executionInfo":{"status":"ok","timestamp":1702617310530,"user_tz":300,"elapsed":920,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# import necessary dependencies\n","import argparse\n","import os, sys\n","import time\n","import datetime\n","from tqdm import tqdm_notebook as tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/ece661/final_project/\")\n"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"rQoLC_Othqz5","executionInfo":{"status":"ok","timestamp":1702617313149,"user_tz":300,"elapsed":507,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[],"source":["import torchvision.models as models\n","import torch.nn as nn\n","\n","def modify_resnet50_for_cifar10(model):\n","    # Replace the first convolutional layer\n","    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","    # Remove the first max pooling layer\n","    model.maxpool = nn.Identity()\n","    return model\n","\n","base_encoder = models.resnet50(pretrained=False)\n","base_encoder = modify_resnet50_for_cifar10(base_encoder)\n","base_encoder = nn.Sequential(*list(base_encoder.children())[:-1])\n","\n","# Define the projection head\n","class ProjectionHead(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(ProjectionHead, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Assuming output of ResNet50 is 2048, hidden layer of 512, and output of 128\n","projection_head = ProjectionHead(input_dim=2048, hidden_dim=512, output_dim=128)\n","\n","# Define the SimCLR model\n","class SimCLR(nn.Module):\n","    def __init__(self, encoder, projection_head):\n","        super(SimCLR, self).__init__()\n","        self.encoder = encoder\n","        self.projection_head = projection_head\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = torch.flatten(x, start_dim=1)  # Flatten the output\n","        x = self.projection_head(x)\n","        return x\n","\n","# Initialize the model\n","model = SimCLR(base_encoder, projection_head)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UmOwQtY9OwrJ","outputId":"bf69df8d-df34-4f2a-8f14-3b13f606312b","executionInfo":{"status":"ok","timestamp":1702610215685,"user_tz":300,"elapsed":183,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["base_encoder: Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU(inplace=True)\n","  (3): Identity()\n","  (4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (5): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (6): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (7): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",")\n"]}],"source":["print(\"base_encoder:\", base_encoder)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"1299Rzf4u0Sy","executionInfo":{"status":"ok","timestamp":1702617320039,"user_tz":300,"elapsed":163,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[],"source":["class NTXentLoss(torch.nn.Module):\n","    def __init__(self, temperature, device):\n","        super(NTXentLoss, self).__init__()\n","        self.temperature = temperature\n","        self.device = device\n","        self.cossim = torch.nn.CosineSimilarity(dim=2)\n","\n","    def forward(self, z_i, z_j):\n","        N = 2 * z_i.size(0)  # Dynamically calculate based on input size\n","        z = torch.cat((z_i, z_j), dim=0)\n","\n","        sim = self.cossim(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n","        sim_i_j = torch.diag(sim, z_i.size(0))\n","        sim_j_i = torch.diag(sim, -z_i.size(0))\n","\n","        # Ensure the mask is created based on the dynamic size\n","        mask = torch.ones((N, N), dtype=bool, device=self.device)\n","        mask = mask.fill_diagonal_(0)\n","        for i in range(z_i.size(0)):\n","            mask[i, z_i.size(0) + i] = 0\n","            mask[z_i.size(0) + i, i] = 0\n","\n","        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n","        negative_samples = sim[mask].reshape(N, -1)\n","\n","        labels = torch.zeros(N, device=self.device).long()\n","        logits = torch.cat((positive_samples, negative_samples), dim=1)\n","        loss = F.cross_entropy(logits, labels)\n","        return loss\n"]},{"cell_type":"markdown","metadata":{"id":"o0rUPKHphqz7"},"source":["## Step 1: Set up preprocessing functions\n","Preprocessing is very important as discussed in the lecture.\n","You will need to write preprocessing functions with the help of *torchvision.transforms* in this step.\n","You can find helpful tutorial/API at [here](https://pytorch.org/vision/stable/transforms.html)."]},{"cell_type":"markdown","metadata":{"id":"8E4dITCohqz7"},"source":["## Step 2: Set up dataset and dataloader\n","\n"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"1MeaLfaTwnEl","executionInfo":{"status":"ok","timestamp":1702617323307,"user_tz":300,"elapsed":139,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[],"source":["from torchvision.datasets import CIFAR10\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","\n","class SimCLRDataset(Dataset):\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image, label = self.dataset[idx]\n","\n","        # Apply the transformation to get two augmented versions of the same image\n","        if self.transform:\n","            image1 = self.transform(image)\n","            image2 = self.transform(image)\n","\n","        return image1, image2"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RVZ-nosCzGVM","outputId":"1849abc6-476a-48ec-b276-415506451f2c","executionInfo":{"status":"ok","timestamp":1702617330844,"user_tz":300,"elapsed":3855,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# useful libraries\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Data transformation\n","mean = (0.4914, 0.4822, 0.4465)\n","std = (0.2470, 0.2435, 0.2616)\n","\n","from torchvision import transforms\n","\n","def get_color_distortion(s=1.0):\n","    # s is the strength of color distortion.\n","    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n","    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n","    rnd_gray = transforms.RandomGrayscale(p=0.2)\n","    color_distort = transforms.Compose([\n","        rnd_color_jitter,\n","        rnd_gray\n","    ])\n","    return color_distort\n","\n","# Data transformation for CIFAR-10\n","transform_train = transforms.Compose([\n","    # Inception-style crop and resize to 32x32\n","    transforms.RandomResizedCrop(32, scale=(0.08, 1.0), ratio=(3. / 4., 4. / 3.)),\n","    transforms.RandomHorizontalFlip(),\n","    get_color_distortion(s=0.5),  # Color distortion with strength 0.5\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","\n","transform_classify = transforms.Compose(\n","                            [transforms.ToTensor(),\n","                             transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n","\n","# Load CIFAR10 dataset\n","DATA_ROOT = \"./data\"\n","TRAIN_BATCH_SIZE = 256\n","\n","train_set = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=None)\n","train_dataset = SimCLRDataset(train_set, transform=transform_train)\n","\n","tra_set = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform_classify)\n","val_set = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform_classify)\n","\n","# DataLoader for SimCLR\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=4\n",")"]},{"cell_type":"markdown","metadata":{"id":"f-KkR1bYhqz8"},"source":["## Step 3: Instantiate your model and deploy it to GPU devices.\n"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWblmjOxhqz8","outputId":"b756a97c-23b3-41e1-97ae-4b34c5f517d1","executionInfo":{"status":"ok","timestamp":1702617332076,"user_tz":300,"elapsed":147,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":48}],"source":["# specify the device for computation\n","#############################################\n","# Determine if a GPU is available\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","\n","next(model.parameters()).device\n","\n","#############################################"]},{"cell_type":"markdown","metadata":{"id":"3Ol6-DZqhqz8"},"source":["## Step 4: Set up the loss function and optimizer\n"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"WsHHeCPLhqz8","executionInfo":{"status":"ok","timestamp":1702617336267,"user_tz":300,"elapsed":142,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Hyperparameters\n","INITIAL_LR = 0.5\n","MOMENTUM = 0.9\n","REG = 1e-4\n","\n","# Initialize the NT-Xent loss (contrastive loss) for SimCLR\n","temperature = 0.5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","criterion = NTXentLoss(temperature, device)\n","\n","# Add optimizer\n","optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n"]},{"cell_type":"markdown","metadata":{"id":"Z99cT8VAhqz8"},"source":["## Step 5: Start the training process.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMg8BHO9usD1","outputId":"426f576d-c774-4ffc-a15d-6dd0f2840c7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["==> Training starts!\n","==================================================\n","Epoch [61/100], Loss: 4.8436\n","Epoch [62/100], Loss: 4.8421\n","Epoch [63/100], Loss: 4.8464\n","Epoch [64/100], Loss: 4.8400\n","Epoch [65/100], Loss: 4.8376\n","Epoch [66/100], Loss: 4.8331\n","Epoch [67/100], Loss: 4.8341\n","Epoch [68/100], Loss: 4.8372\n","Epoch [69/100], Loss: 4.8345\n","Epoch [70/100], Loss: 4.8340\n","Epoch [71/100], Loss: 4.8383\n","Epoch [72/100], Loss: 4.8369\n","Epoch [73/100], Loss: 4.8292\n","Epoch [74/100], Loss: 4.8314\n","Epoch [75/100], Loss: 4.8276\n","Epoch [76/100], Loss: 4.8316\n","Epoch [77/100], Loss: 4.8285\n","Epoch [78/100], Loss: 4.8332\n","Epoch [79/100], Loss: 4.8288\n","Epoch [80/100], Loss: 4.8228\n","Epoch [81/100], Loss: 4.8290\n","Epoch [82/100], Loss: 4.8207\n","Epoch [83/100], Loss: 4.8250\n","Epoch [84/100], Loss: 4.8258\n","Epoch [85/100], Loss: 4.8219\n","Epoch [86/100], Loss: 4.8213\n","Epoch [87/100], Loss: 4.8227\n","Epoch [88/100], Loss: 4.8195\n","Epoch [89/100], Loss: 4.8183\n","Epoch [90/100], Loss: 4.8199\n","Epoch [91/100], Loss: 4.8221\n","Epoch [92/100], Loss: 4.8163\n","Epoch [93/100], Loss: 4.8190\n","Epoch [94/100], Loss: 4.8166\n","Epoch [95/100], Loss: 4.8186\n","Epoch [96/100], Loss: 4.8167\n","Epoch [97/100], Loss: 4.8175\n","Epoch [98/100], Loss: 4.8184\n","Epoch [99/100], Loss: 4.8178\n","Epoch [100/100], Loss: 4.8149\n","==================================================\n","==> Training complete\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","model.load_state_dict(torch.load('/content/drive/MyDrive/ece661/final_project/saved_model/simclr_epoch_59.pth'))\n","\n","print(\"==> Training starts!\")\n","print(\"=\" * 50)\n","\n","# Learning rate decay setup\n","current_learning_rate = INITIAL_LR\n","EPOCHS = 40\n","CHECKPOINT_FOLDER = \"/content/drive/MyDrive/ece661/final_project/saved_model\"\n","\n","# Training loop\n","for epoch in range(60, 60+EPOCHS):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch_idx, (image1, image2) in enumerate(train_loader):\n","        # Check if image1 and image2 have the same dimensions\n","        if image1.dim() != 4 or image2.dim() != 4:\n","            raise ValueError(f\"Expected images to have 4 dimensions. Got {image1.dim()} and {image2.dim()}\")\n","\n","        optimizer.zero_grad()\n","\n","        image1 = image1.to(device)\n","        image2 = image2.to(device)\n","\n","        # Concatenate the pairs of images along the batch dimension\n","        concatenated_images = torch.cat((image1, image2), dim=0)\n","\n","        ## Forward pass and calculate loss\n","        representations = model(concatenated_images)\n","\n","        # Split the representations into two halves\n","        z_i, z_j = torch.split(representations, representations.shape[0] // 2, dim=0)\n","\n","        # Calculate loss using both halves\n","        loss = criterion(z_i, z_j)\n","        total_loss += loss.item()\n","\n","        # Backward and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(\"Epoch [%d/%d], Loss: %.4f\" % (epoch + 1, EPOCHS+60, avg_loss))\n","\n","    # Save checkpoint\n","    if not os.path.exists(CHECKPOINT_FOLDER):\n","        os.makedirs(CHECKPOINT_FOLDER)\n","    torch.save(model.state_dict(), os.path.join(CHECKPOINT_FOLDER, 'simclr_epoch_%d.pth' % epoch))\n","\n","print(\"=\" * 50)\n","print(\"==> Training complete\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_hCbf27LPq-","outputId":"214a5e05-4977-4e1c-b01a-fa663d2f8505"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('/content/drive/MyDrive/ece661/final_project/saved_model/simclr_epoch_99.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqM1SJGT9BX6"},"outputs":[],"source":["model.projection_head = nn.Linear(2048, 10)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"zGB8Fv9D9DKd","executionInfo":{"status":"ok","timestamp":1702616568030,"user_tz":300,"elapsed":158,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[],"source":["\n","normal_train_loader = DataLoader(\n","    tra_set,\n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=4\n",")\n","normal_validate_loader = DataLoader(\n","    val_set,\n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=4\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02eBeA189Gwc","outputId":"d8e8299d-051b-45a0-a416-d1ed93412124"},"outputs":[{"name":"stdout","output_type":"stream","text":["==> Training starts!\n","==================================================\n","Epoch [1/20], Loss: 0.7591\n","Epoch [1/20], Time: 160.9204\n","Validation loss: 0.0188, Validation accuracy: 0.7111\n","Epoch [2/20], Loss: 0.5068\n","Epoch [2/20], Time: 166.8976\n","Validation loss: 0.0407, Validation accuracy: 0.7356\n","Epoch [3/20], Loss: 0.4046\n","Epoch [3/20], Time: 167.5639\n","Validation loss: 0.0123, Validation accuracy: 0.7821\n","Epoch [4/20], Loss: 0.3500\n","Epoch [4/20], Time: 167.6127\n","Validation loss: 0.0343, Validation accuracy: 0.7460\n","Epoch [5/20], Loss: 0.3000\n","Epoch [5/20], Time: 167.5665\n","Validation loss: 0.0357, Validation accuracy: 0.7798\n","Epoch [6/20], Loss: 0.2679\n","Epoch [6/20], Time: 167.6067\n","Validation loss: 0.0141, Validation accuracy: 0.7672\n","Epoch [7/20], Loss: 0.2440\n","Epoch [7/20], Time: 166.7209\n","Validation loss: 0.0477, Validation accuracy: 0.7554\n","Epoch [8/20], Loss: 0.2258\n","Epoch [8/20], Time: 166.4949\n","Validation loss: 0.0143, Validation accuracy: 0.8230\n","Epoch [9/20], Loss: 0.2045\n","Epoch [9/20], Time: 167.4019\n","Validation loss: 0.0071, Validation accuracy: 0.8287\n","Epoch [10/20], Loss: 0.1875\n","Epoch [10/20], Time: 166.5710\n","Validation loss: 0.0408, Validation accuracy: 0.8205\n","Epoch [11/20], Loss: 0.1818\n","Epoch [11/20], Time: 167.3812\n","Validation loss: 0.0123, Validation accuracy: 0.8181\n","Epoch [12/20], Loss: 0.1624\n","Epoch [12/20], Time: 166.8960\n","Validation loss: 0.0319, Validation accuracy: 0.8228\n","Epoch [13/20], Loss: 0.1604\n","Epoch [13/20], Time: 166.8473\n","Validation loss: 0.0167, Validation accuracy: 0.8316\n","Epoch [14/20], Loss: 0.1604\n","Epoch [14/20], Time: 166.9286\n","Validation loss: 0.0096, Validation accuracy: 0.7717\n","Epoch [15/20], Loss: 0.1494\n","Epoch [15/20], Time: 166.8335\n","Validation loss: 0.0182, Validation accuracy: 0.7742\n","Epoch [16/20], Loss: 0.1515\n","Epoch [16/20], Time: 166.9283\n","Validation loss: 0.0247, Validation accuracy: 0.7897\n","Epoch [17/20], Loss: 0.1491\n","Epoch [17/20], Time: 166.5400\n","Validation loss: 0.0460, Validation accuracy: 0.7872\n","Epoch [18/20], Loss: 0.1295\n","Epoch [18/20], Time: 166.7988\n","Validation loss: 0.0152, Validation accuracy: 0.8053\n","Epoch [19/20], Loss: 0.1359\n","Epoch [19/20], Time: 166.6816\n","Validation loss: 0.0155, Validation accuracy: 0.8423\n","Epoch [20/20], Loss: 0.1270\n","Epoch [20/20], Time: 166.6932\n","Validation loss: 0.0021, Validation accuracy: 0.8110\n","==================================================\n","==> Training complete\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","print(\"==> Training starts!\")\n","print(\"=\" * 50)\n","\n","# Learning rate decay setup\n","DECAY_EPOCHS = 5\n","DECAY = 0.8\n","current_learning_rate = INITIAL_LR\n","EPOCHS = 20\n","CHECKPOINT_FOLDER = \"/content/drive/MyDrive/ece661/final_project/saved_model\"\n","\n","# Training loop\n","start_time = time.time()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n","for epoch in range(0, 20):\n","\n","    # if epoch % DECAY_EPOCHS == 0 and epoch != 0:\n","    #     current_learning_rate *= DECAY\n","    #     for param_group in optimizer.param_groups:\n","    #         param_group['lr'] = current_learning_rate\n","    #     print(\"Current learning rate has decayed to %f\" % current_learning_rate)\n","\n","\n","    model.train()\n","    total_loss = 0\n","\n","    for batch_idx, (image, label) in enumerate(normal_train_loader):\n","        # Check if image1 and image2 have the same dimensions\n","        # if image1.dim() != 4 or image2.dim() != 4:\n","        #     raise ValueError(f\"Expected images to have 4 dimensions. Got {image1.dim()} and {image2.dim()}\")\n","\n","        image = image.to(device)\n","        label = label.to(device)\n","\n","        # compute the output and loss\n","        output = model.forward(image)\n","        loss = criterion(output, label)\n","        train_loss = loss.detach()\n","\n","        # zero the gradient\n","        optimizer.zero_grad()\n","\n","        # backpropagation\n","        loss.backward()\n","\n","        # apply gradient and update the weights\n","        optimizer.step()\n","\n","        total_loss += train_loss\n","\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(\"Epoch [%d/%d], Loss: %.4f\" % (epoch + 1, EPOCHS, avg_loss))\n","    end_time = time.time()\n","    print(\"Epoch [%d/%d], Time: %.4f\" % (epoch + 1, EPOCHS, end_time-start_time))\n","    start_time = end_time\n","\n","    model.eval()\n","    correct_examples = 0\n","    total_examples = 0\n","    val_loss = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(normal_validate_loader):\n","            ####################################\n","            # your code here\n","            # copy inputs to device\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","\n","            # compute the output and loss\n","            output = model.forward(inputs)\n","            loss = criterion(output, targets)\n","            val_loss = loss.detach()\n","\n","            # count the number of correctly predicted samples in the current batch\n","            _, predicted_results = torch.max(output, 1)\n","            correct_predictions = (predicted_results == targets)\n","            correct_examples += correct_predictions.sum().item()\n","            total_examples += len(targets)\n","            ####################################\n","\n","    avg_loss = val_loss / len(normal_validate_loader)\n","    avg_acc = correct_examples / total_examples\n","    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n","\n","\n","\n","print(\"=\" * 50)\n","print(\"==> Training complete\")\n","\n","# Save checkpoint\n","if not os.path.exists(CHECKPOINT_FOLDER):\n","    os.makedirs(CHECKPOINT_FOLDER)\n","torch.save(model.state_dict(), os.path.join(CHECKPOINT_FOLDER, 'simclr_with_decoder_epoch_%d.pth' % epoch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZNt6em8-kJF"},"outputs":[],"source":["# sample_sizes = [2500, 5000, 7500, 10000]\n","# sample_sizes = [500, 1000, 2000, 3000, 4000]\n","sample_size = 50000\n","model.load_state_dict(torch.load('/content/drive/MyDrive/ece661/final_project/saved_model/simclr_epoch_99.pth'))\n","\n","model.projection_head = nn.Linear(2048, 10)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z77jcozdty8_","outputId":"cb604121-f03d-4c79-e96a-64b415ba1005","executionInfo":{"status":"ok","timestamp":1702615459610,"user_tz":300,"elapsed":3428912,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["==> Training with 50000 samples starts!\n","==================================================\n","Epoch [1/20], Loss: 0.7550\n","Epoch [1/20], Time: 154.1889\n","Validation loss: 0.0403, Validation accuracy: 0.6672\n","==================================================\n","Epoch [2/20], Loss: 0.4984\n","Epoch [2/20], Time: 171.7484\n","Validation loss: 0.0120, Validation accuracy: 0.7618\n","==================================================\n","Epoch [3/20], Loss: 0.4083\n","Epoch [3/20], Time: 171.8981\n","Validation loss: 0.0075, Validation accuracy: 0.7626\n","==================================================\n","Epoch [4/20], Loss: 0.3430\n","Epoch [4/20], Time: 172.6007\n","Validation loss: 0.0084, Validation accuracy: 0.8198\n","==================================================\n","Epoch [5/20], Loss: 0.2983\n","Epoch [5/20], Time: 171.5429\n","Validation loss: 0.0238, Validation accuracy: 0.7361\n","==================================================\n","Epoch [6/20], Loss: 0.2671\n","Epoch [6/20], Time: 172.0915\n","Validation loss: 0.0201, Validation accuracy: 0.7719\n","==================================================\n","Epoch [7/20], Loss: 0.2332\n","Epoch [7/20], Time: 173.0508\n","Validation loss: 0.0419, Validation accuracy: 0.7385\n","==================================================\n","Epoch [8/20], Loss: 0.2139\n","Epoch [8/20], Time: 171.5201\n","Validation loss: 0.0291, Validation accuracy: 0.7696\n","==================================================\n","Epoch [9/20], Loss: 0.1925\n","Epoch [9/20], Time: 171.7919\n","Validation loss: 0.0241, Validation accuracy: 0.8135\n","==================================================\n","Epoch [10/20], Loss: 0.1900\n","Epoch [10/20], Time: 171.9034\n","Validation loss: 0.0066, Validation accuracy: 0.8195\n","==================================================\n","Epoch [11/20], Loss: 0.1771\n","Epoch [11/20], Time: 171.6928\n","Validation loss: 0.0189, Validation accuracy: 0.7957\n","==================================================\n","Epoch [12/20], Loss: 0.1771\n","Epoch [12/20], Time: 171.9084\n","Validation loss: 0.0125, Validation accuracy: 0.8084\n","==================================================\n","Epoch [13/20], Loss: 0.1652\n","Epoch [13/20], Time: 171.7949\n","Validation loss: 0.0063, Validation accuracy: 0.8168\n","==================================================\n","Epoch [14/20], Loss: 0.1492\n","Epoch [14/20], Time: 171.9244\n","Validation loss: 0.0040, Validation accuracy: 0.8086\n","==================================================\n","Epoch [15/20], Loss: 0.1433\n","Epoch [15/20], Time: 171.4872\n","Validation loss: 0.0164, Validation accuracy: 0.8204\n","==================================================\n","Epoch [16/20], Loss: 0.1546\n","Epoch [16/20], Time: 171.8647\n","Validation loss: 0.0149, Validation accuracy: 0.8295\n","==================================================\n","Epoch [17/20], Loss: 0.1333\n","Epoch [17/20], Time: 171.6639\n","Validation loss: 0.0039, Validation accuracy: 0.8241\n","==================================================\n","Epoch [18/20], Loss: 0.1462\n","Epoch [18/20], Time: 171.6377\n","Validation loss: 0.0578, Validation accuracy: 0.7873\n","==================================================\n","Epoch [19/20], Loss: 0.1390\n","Epoch [19/20], Time: 171.4949\n","Validation loss: 0.0055, Validation accuracy: 0.8258\n","==================================================\n","Epoch [20/20], Loss: 0.1321\n","Epoch [20/20], Time: 171.4902\n","Validation loss: 0.0240, Validation accuracy: 0.7649\n","==================================================\n","==> Training with 50000 samples complete\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Subset\n","\n","\n","# 选择子集\n","subset_indices = torch.randperm(len(tra_set))[:sample_size]\n","train_subset = Subset(tra_set, subset_indices)\n","\n","# 创建新的DataLoader\n","normal_train_loader_splite = DataLoader(\n","    train_subset,\n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=4\n",")\n","\n","\n","print(f\"==> Training with {sample_size} samples starts!\")\n","# print(\"==> Training starts!\")\n","print(\"=\" * 50)\n","\n","# Learning rate decay setup\n","DECAY_EPOCHS = 5\n","DECAY = 0.8\n","current_learning_rate = INITIAL_LR\n","EPOCHS = 20\n","CHECKPOINT_FOLDER = \"/content/drive/MyDrive/ece661/final_project/saved_model\"\n","\n","# Training loop\n","start_time = time.time()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n","for epoch in range(0, EPOCHS):\n","\n","    # if epoch % DECAY_EPOCHS == 0 and epoch != 0:\n","    #     current_learning_rate *= DECAY\n","    #     for param_group in optimizer.param_groups:\n","    #         param_group['lr'] = current_learning_rate\n","    #     print(\"Current learning rate has decayed to %f\" % current_learning_rate)\n","\n","\n","    model.train()\n","    total_loss = 0\n","\n","    for batch_idx, (image, label) in enumerate(normal_train_loader_splite):\n","        # Check if image1 and image2 have the same dimensions\n","        # if image1.dim() != 4 or image2.dim() != 4:\n","        #     raise ValueError(f\"Expected images to have 4 dimensions. Got {image1.dim()} and {image2.dim()}\")\n","\n","        image = image.to(device)\n","        label = label.to(device)\n","\n","        # compute the output and loss\n","        output = model.forward(image)\n","        loss = criterion(output, label)\n","        train_loss = loss.detach()\n","\n","        # zero the gradient\n","        optimizer.zero_grad()\n","\n","        # backpropagation\n","        loss.backward()\n","\n","        # apply gradient and update the weights\n","        optimizer.step()\n","\n","        total_loss += train_loss\n","\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(\"Epoch [%d/%d], Loss: %.4f\" % (epoch + 1, EPOCHS, avg_loss))\n","    end_time = time.time()\n","    print(\"Epoch [%d/%d], Time: %.4f\" % (epoch + 1, EPOCHS, end_time-start_time))\n","    start_time = end_time\n","\n","    model.eval()\n","    correct_examples = 0\n","    total_examples = 0\n","    val_loss = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(normal_validate_loader):\n","            ####################################\n","            # your code here\n","            # copy inputs to device\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","\n","            # compute the output and loss\n","            output = model.forward(inputs)\n","            loss = criterion(output, targets)\n","            val_loss = loss.detach()\n","\n","            # count the number of correctly predicted samples in the current batch\n","            _, predicted_results = torch.max(output, 1)\n","            correct_predictions = (predicted_results == targets)\n","            correct_examples += correct_predictions.sum().item()\n","            total_examples += len(targets)\n","            ####################################\n","\n","    avg_loss = val_loss / len(normal_validate_loader)\n","    avg_acc = correct_examples / total_examples\n","    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n","\n","\n","\n","    print(\"=\" * 50)\n","\n","# Save checkpoint\n","if not os.path.exists(CHECKPOINT_FOLDER):\n","    os.makedirs(CHECKPOINT_FOLDER)\n","torch.save(model.state_dict(), os.path.join(CHECKPOINT_FOLDER, 'New_simclr_with_decoder_epoch_%d_size_%d.pth' % (20, sample_size)))\n","print(f\"==> Training with {sample_size} samples complete\")"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"PqbkyibLMf52","executionInfo":{"status":"ok","timestamp":1702617348591,"user_tz":300,"elapsed":331,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[],"source":["sample_sizes = 10000\n","model.load_state_dict(torch.load('/content/drive/MyDrive/ece661/final_project/saved_model/simclr_epoch_99.pth'))\n","\n","model.projection_head = nn.Linear(2048, 10)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"jb3pDkhrKa0G","executionInfo":{"status":"ok","timestamp":1702617350674,"user_tz":300,"elapsed":140,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[],"source":["for param in model.encoder.parameters():\n","    param.requires_grad = False\n"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xzldxx8HKbKC","outputId":"07d7e646-b62c-4fc5-8de2-726741794f39","executionInfo":{"status":"ok","timestamp":1702618508919,"user_tz":300,"elapsed":1153949,"user":{"displayName":"Kao Andy","userId":"13122838502482801295"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["==> Training starts!\n","==================================================\n","Epoch [1/20], Loss: 1.5312\n","Epoch [1/20], Time: 49.6071\n","Validation loss: 0.0245, Validation accuracy: 0.6682\n","Epoch [2/20], Loss: 1.0794\n","Epoch [2/20], Time: 56.8878\n","Validation loss: 0.0284, Validation accuracy: 0.6799\n","Epoch [3/20], Loss: 0.9815\n","Epoch [3/20], Time: 57.5189\n","Validation loss: 0.0279, Validation accuracy: 0.6895\n","Epoch [4/20], Loss: 0.9345\n","Epoch [4/20], Time: 57.4437\n","Validation loss: 0.0154, Validation accuracy: 0.6949\n","Epoch [5/20], Loss: 0.9053\n","Epoch [5/20], Time: 57.4022\n","Validation loss: 0.0345, Validation accuracy: 0.7000\n","Epoch [6/20], Loss: 0.8860\n","Epoch [6/20], Time: 57.0577\n","Validation loss: 0.0287, Validation accuracy: 0.7013\n","Epoch [7/20], Loss: 0.8710\n","Epoch [7/20], Time: 57.3084\n","Validation loss: 0.0193, Validation accuracy: 0.7072\n","Epoch [8/20], Loss: 0.8576\n","Epoch [8/20], Time: 57.3659\n","Validation loss: 0.0249, Validation accuracy: 0.7067\n","Epoch [9/20], Loss: 0.8467\n","Epoch [9/20], Time: 57.3925\n","Validation loss: 0.0159, Validation accuracy: 0.7090\n","Epoch [10/20], Loss: 0.8383\n","Epoch [10/20], Time: 57.4945\n","Validation loss: 0.0114, Validation accuracy: 0.7120\n","Epoch [11/20], Loss: 0.8316\n","Epoch [11/20], Time: 57.4201\n","Validation loss: 0.0149, Validation accuracy: 0.7117\n","Epoch [12/20], Loss: 0.8278\n","Epoch [12/20], Time: 57.5168\n","Validation loss: 0.0190, Validation accuracy: 0.7124\n","Epoch [13/20], Loss: 0.8201\n","Epoch [13/20], Time: 57.4632\n","Validation loss: 0.0263, Validation accuracy: 0.7124\n","Epoch [14/20], Loss: 0.8146\n","Epoch [14/20], Time: 57.5656\n","Validation loss: 0.0135, Validation accuracy: 0.7153\n","Epoch [15/20], Loss: 0.8097\n","Epoch [15/20], Time: 57.5430\n","Validation loss: 0.0206, Validation accuracy: 0.7155\n","Epoch [16/20], Loss: 0.8060\n","Epoch [16/20], Time: 57.5664\n","Validation loss: 0.0128, Validation accuracy: 0.7165\n","Epoch [17/20], Loss: 0.8023\n","Epoch [17/20], Time: 57.5665\n","Validation loss: 0.0142, Validation accuracy: 0.7182\n","Epoch [18/20], Loss: 0.7981\n","Epoch [18/20], Time: 57.8134\n","Validation loss: 0.0222, Validation accuracy: 0.7164\n","Epoch [19/20], Loss: 0.7952\n","Epoch [19/20], Time: 57.5675\n","Validation loss: 0.0262, Validation accuracy: 0.7205\n","Epoch [20/20], Loss: 0.7912\n","Epoch [20/20], Time: 57.6645\n","Validation loss: 0.0157, Validation accuracy: 0.7212\n","==================================================\n","==> Training complete\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","# Uncomment when continuing...\n","# model.load_state_dict(torch.load('./trained_SIMCLR_model_scripted_classifier.pt'))\n","model = model.to(device)\n","\n","# initial learning rate\n","INITIAL_LR = 0.01\n","# momentum for optimizer\n","MOMENTUM = 0.9\n","# L2 regularization strength\n","REG = 0\n","\n","print(\"==> Training starts!\")\n","print(\"=\" * 50)\n","\n","# Learning rate decay setup\n","DECAY_EPOCHS = 7\n","DECAY = 0.9\n","current_learning_rate = INITIAL_LR\n","EPOCHS = 20\n","\n","# Training loop\n","start_time = time.time()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n","for epoch in range(0, EPOCHS):\n","\n","    # if epoch % DECAY_EPOCHS == 0 and epoch != 0:\n","    #     current_learning_rate *= DECAY\n","    #     for param_group in optimizer.param_groups:\n","    #         param_group['lr'] = current_learning_rate\n","    #     print(\"Current learning rate has decayed to %f\" % current_learning_rate)\n","\n","\n","    model.train()\n","    total_loss = 0\n","\n","    for batch_idx, (image, label) in enumerate(normal_train_loader):\n","        # Check if image1 and image2 have the same dimensions\n","        image = image.to(device)\n","        label = label.to(device)\n","\n","        # compute the output and loss\n","        output = model.forward(image)\n","        loss = criterion(output, label)\n","        train_loss = loss.detach()\n","\n","        # zero the gradient\n","        optimizer.zero_grad()\n","\n","        # backpropagation\n","        loss.backward()\n","\n","        # apply gradient and update the weights\n","        optimizer.step()\n","\n","        total_loss += train_loss\n","\n","\n","    avg_loss = total_loss / len(normal_train_loader)\n","    print(\"Epoch [%d/%d], Loss: %.4f\" % (epoch + 1, EPOCHS, avg_loss))\n","    end_time = time.time()\n","    print(\"Epoch [%d/%d], Time: %.4f\" % (epoch + 1, EPOCHS, end_time-start_time))\n","    start_time = end_time\n","\n","    model.eval()\n","    correct_examples = 0\n","    total_examples = 0\n","    val_loss = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(normal_validate_loader):\n","            ####################################\n","            # your code here\n","            # copy inputs to device\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","\n","            # compute the output and loss\n","            output = model.forward(inputs)\n","            loss = criterion(output, targets)\n","            val_loss = loss.detach()\n","\n","            # count the number of correctly predicted samples in the current batch\n","            _, predicted_results = torch.max(output, 1)\n","            correct_predictions = (predicted_results == targets)\n","            correct_examples += correct_predictions.sum().item()\n","            total_examples += len(targets)\n","            ####################################\n","\n","    avg_loss = val_loss / len(normal_validate_loader)\n","    avg_acc = correct_examples / total_examples\n","    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n","\n","\n","\n","print(\"=\" * 50)\n","print(\"==> Training complete\")\n","\n","# Save checkpoint\n","torch.save(model.state_dict(), '/content/drive/MyDrive/ece661/final_project/saved_model/trained_SIMCLR_classifier_linear_eval.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1 (default, Sep  5 2023, 19:36:56) \n[Clang 14.0.0 (clang-1400.0.29.202)]"},"vscode":{"interpreter":{"hash":"9200b70df9f286590bb66f474ded0efe34db205d5a4c360b3ba5b0889a7b635c"}}},"nbformat":4,"nbformat_minor":0}