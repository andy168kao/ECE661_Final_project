{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PypqqXnhqz4"
      },
      "source": [
        "## Step 0: Set up the SimpleNN model\n",
        "As you have practiced to implement simple neural networks in Homework 1, we just prepare the implementation for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kNDZdI-9hqz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad6886c-2825-4e2a-aaac-59652a95c241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# import necessary dependencies\n",
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# useful libraries\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/ece661/final_project/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rQoLC_Othqz5"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define the base encoder (e.g., ResNet)\n",
        "# base_encoder = models.resnet50(pretrained=False)\n",
        "# Remove the final fully connected layer\n",
        "# base_encoder = nn.Sequential(*list(base_encoder.children())[:-1])\n",
        "\n",
        "\n",
        "class ResNetEncoder(nn.Module):\n",
        "    def __init__(self, base_model='resnet18'):\n",
        "        super(ResNetEncoder, self).__init__()\n",
        "\n",
        "        # Load the pre-trained base model\n",
        "        if base_model == 'resnet18':\n",
        "            self.base_model = models.resnet18(pretrained=True)\n",
        "        # Add more models as needed\n",
        "\n",
        "        # Modify the first convolution layer\n",
        "        self.base_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        # Remove the fully connected layer\n",
        "        self.base_model.fc = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward through the base model\n",
        "        x = self.base_model.conv1(x)\n",
        "        x = self.base_model.bn1(x)\n",
        "        x = self.base_model.relu(x)\n",
        "\n",
        "        # Skip the maxpool layer\n",
        "        x = self.base_model.layer1(x)\n",
        "        x = self.base_model.layer2(x)\n",
        "        x = self.base_model.layer3(x)\n",
        "        x = self.base_model.layer4(x)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = self.base_model.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Define the projection head\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(ProjectionHead, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Assuming output of ResNet50 is 2048, hidden layer of 512, and output of 128\n",
        "projection_head = ProjectionHead(input_dim=512, output_dim=4)\n",
        "\n",
        "# Define the SimCLR model\n",
        "class RotNet(nn.Module):\n",
        "    def __init__(self, encoder, projection_head):\n",
        "        super(RotNet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.projection_head = projection_head\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = torch.flatten(x, start_dim=1)  # Flatten the output\n",
        "        x = self.projection_head(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_size_in_mib(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.numel() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.numel() * buffer.element_size()\n",
        "    total_size = param_size + buffer_size\n",
        "    total_size_mib = total_size / (1024 ** 2)  # Convert bytes to MiB\n",
        "    return total_size_mib"
      ],
      "metadata": {
        "id": "-BxKGIhWv5Oo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0rUPKHphqz7"
      },
      "source": [
        "## Step 1: Set up preprocessing functions\n",
        "Preprocessing is very important as discussed in the lecture.\n",
        "You will need to write preprocessing functions with the help of *torchvision.transforms* in this step.\n",
        "You can find helpful tutorial/API at [here](https://pytorch.org/vision/stable/transforms.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E4dITCohqz7"
      },
      "source": [
        "## Step 2: Set up dataset and dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RotNetDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, _ = self.dataset[idx]\n",
        "\n",
        "        # Randomly choose a rotation angle (0, 90, 180, 270 degrees)\n",
        "        rotation_label = np.random.choice([0, 1, 2, 3])\n",
        "        rotated_image = image.rotate(rotation_label * 90)\n",
        "\n",
        "        # Convert PIL image to tensor\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        rotated_image = transform(rotated_image)\n",
        "\n",
        "        return rotated_image, rotation_label"
      ],
      "metadata": {
        "id": "1MeaLfaTwnEl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformation\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "DATA_ROOT = \"./data\"\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "\n",
        "# Load the dataset\n",
        "original_dataset = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=None)\n",
        "original_rotational_detection_dataset = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=None)\n",
        "\n",
        "# Wrap it with RotNetDataset\n",
        "rotnet_dataset = RotNetDataset(original_dataset)\n",
        "detection_dataset = RotNetDataset(original_rotational_detection_dataset)\n",
        "\n",
        "# DataLoader\n",
        "trainloader = torch.utils.data.DataLoader(rotnet_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "detectionloader = torch.utils.data.DataLoader(detection_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVZ-nosCzGVM",
        "outputId": "2fa64f05-df06-459b-aa9c-ea50970b9d08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-KkR1bYhqz8"
      },
      "source": [
        "## Step 3: Instantiate your model and deploy it to GPU devices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWblmjOxhqz8",
        "outputId": "1350eff2-49c6-4a55-d137-ad9b7378b4e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# specify the device for computation\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the model\n",
        "base_encoder = ResNetEncoder()\n",
        "model = RotNet(base_encoder, projection_head)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "next(model.parameters()).device\n",
        "\n",
        "#############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ol6-DZqhqz8"
      },
      "source": [
        "## Step 4: Set up the loss function and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WsHHeCPLhqz8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Hyperparameters\n",
        "INITIAL_LR = 0.5\n",
        "MOMENTUM = 0.9\n",
        "REG = 1e-4\n",
        "\n",
        "# Initialize the NT-Xent loss (contrastive loss) for SimCLR\n",
        "temperature = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Add optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z99cT8VAhqz8"
      },
      "source": [
        "## Step 5: Start the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "print(\"==> Training starts!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Learning rate decay setup\n",
        "DECAY_EPOCHS = 10\n",
        "DECAY = 0.9\n",
        "current_learning_rate = INITIAL_LR\n",
        "EPOCHS = 50\n",
        "CHECKPOINT_FOLDER = \"/content/drive/My Drive/ece661/final_project/saved_model_rotnet\"\n",
        "\n",
        "# Training loop\n",
        "start_time = time.time()\n",
        "for epoch in range(50, 50+EPOCHS):\n",
        "\n",
        "    # if epoch % DECAY_EPOCHS == 0 and epoch != 0:\n",
        "    #     current_learning_rate *= DECAY\n",
        "    #     for param_group in optimizer.param_groups:\n",
        "    #         param_group['lr'] = current_learning_rate\n",
        "    #     print(\"Current learning rate has decayed to %f\" % current_learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (image, label) in enumerate(trainloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Concatenate the pairs of images along the batch dimension\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        ## Forward pass and calculate loss\n",
        "        representations = model(image)\n",
        "\n",
        "        # Calculate loss using both halves\n",
        "        loss = criterion(representations, label)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(trainloader)\n",
        "    print(\"Epoch [%d/%d], Loss: %.4f\" % (epoch + 1, EPOCHS+50, avg_loss))\n",
        "    end_time = time.time()\n",
        "    print(\"Epoch [%d/%d], Time: %.4f\" % (epoch + 1, EPOCHS+50, end_time-start_time))\n",
        "    start_time = end_time\n",
        "\n",
        "\n",
        "    correct_examples = 0\n",
        "    total_examples = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(detectionloader):\n",
        "            ####################################\n",
        "            # your code here\n",
        "            # copy inputs to device\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute the output and loss\n",
        "            output = model.forward(inputs)\n",
        "            loss = criterion(output, targets)\n",
        "            val_loss = loss.detach()\n",
        "\n",
        "            # count the number of correctly predicted samples in the current batch\n",
        "            _, predicted_results = torch.max(output, 1)\n",
        "            correct_predictions = (predicted_results == targets)\n",
        "            correct_examples += correct_predictions.sum().item()\n",
        "            total_examples += len(targets)\n",
        "            ####################################\n",
        "\n",
        "    avg_loss = val_loss / len(detectionloader)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "\n",
        "\n",
        "    # Save checkpoint\n",
        "    if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "        os.makedirs(CHECKPOINT_FOLDER)\n",
        "    torch.save(model.state_dict(), os.path.join(CHECKPOINT_FOLDER, 'rotnet_epoch_%d.pth' % epoch))\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"==> Training complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMg8BHO9usD1",
        "outputId": "c5eadc96-1642-4e43-aeb6-95bf5c74f962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch [51/100], Loss: 0.4001\n",
            "Epoch [51/100], Time: 23.8746\n",
            "Validation loss: 0.0110, Validation accuracy: 0.8168\n",
            "Epoch [52/100], Loss: 0.3862\n",
            "Epoch [52/100], Time: 28.3914\n",
            "Validation loss: 0.0254, Validation accuracy: 0.8114\n",
            "Epoch [53/100], Loss: 0.3816\n",
            "Epoch [53/100], Time: 28.5796\n",
            "Validation loss: 0.0153, Validation accuracy: 0.8035\n",
            "Epoch [54/100], Loss: 0.3804\n",
            "Epoch [54/100], Time: 28.3502\n",
            "Validation loss: 0.0068, Validation accuracy: 0.8075\n",
            "Epoch [55/100], Loss: 0.3792\n",
            "Epoch [55/100], Time: 28.3964\n",
            "Validation loss: 0.0133, Validation accuracy: 0.8043\n",
            "Epoch [56/100], Loss: 0.3671\n",
            "Epoch [56/100], Time: 28.7215\n",
            "Validation loss: 0.0043, Validation accuracy: 0.8300\n",
            "Epoch [57/100], Loss: 0.3627\n",
            "Epoch [57/100], Time: 29.0695\n",
            "Validation loss: 0.0135, Validation accuracy: 0.8100\n",
            "Epoch [58/100], Loss: 0.3632\n",
            "Epoch [58/100], Time: 28.6798\n",
            "Validation loss: 0.0116, Validation accuracy: 0.8131\n",
            "Epoch [59/100], Loss: 0.3645\n",
            "Epoch [59/100], Time: 29.1189\n",
            "Validation loss: 0.0178, Validation accuracy: 0.8338\n",
            "Epoch [60/100], Loss: 0.3499\n",
            "Epoch [60/100], Time: 28.9734\n",
            "Validation loss: 0.0151, Validation accuracy: 0.7876\n",
            "Epoch [61/100], Loss: 0.3492\n",
            "Epoch [61/100], Time: 29.5861\n",
            "Validation loss: 0.0034, Validation accuracy: 0.8050\n",
            "Epoch [62/100], Loss: 0.3442\n",
            "Epoch [62/100], Time: 28.7268\n",
            "Validation loss: 0.0080, Validation accuracy: 0.8207\n",
            "Epoch [63/100], Loss: 0.3394\n",
            "Epoch [63/100], Time: 28.5562\n",
            "Validation loss: 0.0060, Validation accuracy: 0.8088\n",
            "Epoch [64/100], Loss: 0.3359\n",
            "Epoch [64/100], Time: 28.8391\n",
            "Validation loss: 0.0127, Validation accuracy: 0.8302\n",
            "Epoch [65/100], Loss: 0.3345\n",
            "Epoch [65/100], Time: 28.8403\n",
            "Validation loss: 0.0051, Validation accuracy: 0.8101\n",
            "Epoch [66/100], Loss: 0.3311\n",
            "Epoch [66/100], Time: 28.9130\n",
            "Validation loss: 0.0170, Validation accuracy: 0.8050\n",
            "Epoch [67/100], Loss: 0.3289\n",
            "Epoch [67/100], Time: 28.8637\n",
            "Validation loss: 0.0137, Validation accuracy: 0.7845\n",
            "Epoch [68/100], Loss: 0.3273\n",
            "Epoch [68/100], Time: 28.7222\n",
            "Validation loss: 0.0248, Validation accuracy: 0.8229\n",
            "Epoch [69/100], Loss: 0.3208\n",
            "Epoch [69/100], Time: 28.8142\n",
            "Validation loss: 0.0033, Validation accuracy: 0.8279\n",
            "Epoch [70/100], Loss: 0.3203\n",
            "Epoch [70/100], Time: 29.2021\n",
            "Validation loss: 0.0098, Validation accuracy: 0.8193\n",
            "Epoch [71/100], Loss: 0.3143\n",
            "Epoch [71/100], Time: 28.9187\n",
            "Validation loss: 0.0116, Validation accuracy: 0.8055\n",
            "Epoch [72/100], Loss: 0.3202\n",
            "Epoch [72/100], Time: 28.7045\n",
            "Validation loss: 0.0061, Validation accuracy: 0.8318\n",
            "Epoch [73/100], Loss: 0.3118\n",
            "Epoch [73/100], Time: 28.6830\n",
            "Validation loss: 0.0225, Validation accuracy: 0.8097\n",
            "Epoch [74/100], Loss: 0.3108\n",
            "Epoch [74/100], Time: 28.3431\n",
            "Validation loss: 0.0207, Validation accuracy: 0.8363\n",
            "Epoch [75/100], Loss: 0.3029\n",
            "Epoch [75/100], Time: 28.3515\n",
            "Validation loss: 0.0207, Validation accuracy: 0.8362\n",
            "Epoch [76/100], Loss: 0.3075\n",
            "Epoch [76/100], Time: 28.7918\n",
            "Validation loss: 0.0116, Validation accuracy: 0.8250\n",
            "Epoch [77/100], Loss: 0.3065\n",
            "Epoch [77/100], Time: 28.7355\n",
            "Validation loss: 0.0136, Validation accuracy: 0.8379\n",
            "Epoch [78/100], Loss: 0.3012\n",
            "Epoch [78/100], Time: 28.6010\n",
            "Validation loss: 0.0093, Validation accuracy: 0.7882\n",
            "Epoch [79/100], Loss: 0.2952\n",
            "Epoch [79/100], Time: 28.3383\n",
            "Validation loss: 0.0237, Validation accuracy: 0.8122\n",
            "Epoch [80/100], Loss: 0.3017\n",
            "Epoch [80/100], Time: 28.7555\n",
            "Validation loss: 0.0142, Validation accuracy: 0.8171\n",
            "Epoch [81/100], Loss: 0.2962\n",
            "Epoch [81/100], Time: 29.0722\n",
            "Validation loss: 0.0149, Validation accuracy: 0.8267\n",
            "Epoch [82/100], Loss: 0.2967\n",
            "Epoch [82/100], Time: 28.7367\n",
            "Validation loss: 0.0064, Validation accuracy: 0.8324\n",
            "Epoch [83/100], Loss: 0.2902\n",
            "Epoch [83/100], Time: 28.5058\n",
            "Validation loss: 0.0011, Validation accuracy: 0.8110\n",
            "Epoch [84/100], Loss: 0.2893\n",
            "Epoch [84/100], Time: 28.9335\n",
            "Validation loss: 0.0144, Validation accuracy: 0.8074\n",
            "Epoch [85/100], Loss: 0.2934\n",
            "Epoch [85/100], Time: 28.5538\n",
            "Validation loss: 0.0083, Validation accuracy: 0.8377\n",
            "Epoch [86/100], Loss: 0.2865\n",
            "Epoch [86/100], Time: 28.7700\n",
            "Validation loss: 0.0223, Validation accuracy: 0.7938\n",
            "Epoch [87/100], Loss: 0.2870\n",
            "Epoch [87/100], Time: 28.6414\n",
            "Validation loss: 0.0190, Validation accuracy: 0.8292\n",
            "Epoch [88/100], Loss: 0.2854\n",
            "Epoch [88/100], Time: 28.6981\n",
            "Validation loss: 0.0193, Validation accuracy: 0.8312\n",
            "Epoch [89/100], Loss: 0.2900\n",
            "Epoch [89/100], Time: 28.8212\n",
            "Validation loss: 0.0074, Validation accuracy: 0.8184\n",
            "Epoch [90/100], Loss: 0.2898\n",
            "Epoch [90/100], Time: 28.7509\n",
            "Validation loss: 0.0195, Validation accuracy: 0.8352\n",
            "Epoch [91/100], Loss: 0.2868\n",
            "Epoch [91/100], Time: 28.8590\n",
            "Validation loss: 0.0031, Validation accuracy: 0.8352\n",
            "Epoch [92/100], Loss: 0.2796\n",
            "Epoch [92/100], Time: 28.9833\n",
            "Validation loss: 0.0128, Validation accuracy: 0.8219\n",
            "Epoch [93/100], Loss: 0.2859\n",
            "Epoch [93/100], Time: 28.7805\n",
            "Validation loss: 0.0149, Validation accuracy: 0.8368\n",
            "Epoch [94/100], Loss: 0.2765\n",
            "Epoch [94/100], Time: 28.8291\n",
            "Validation loss: 0.0165, Validation accuracy: 0.8134\n",
            "Epoch [95/100], Loss: 0.2776\n",
            "Epoch [95/100], Time: 28.7094\n",
            "Validation loss: 0.0097, Validation accuracy: 0.8204\n",
            "Epoch [96/100], Loss: 0.2801\n",
            "Epoch [96/100], Time: 28.7708\n",
            "Validation loss: 0.0114, Validation accuracy: 0.8420\n",
            "Epoch [97/100], Loss: 0.2786\n",
            "Epoch [97/100], Time: 28.5877\n",
            "Validation loss: 0.0124, Validation accuracy: 0.8241\n",
            "Epoch [98/100], Loss: 0.2773\n",
            "Epoch [98/100], Time: 28.4106\n",
            "Validation loss: 0.0108, Validation accuracy: 0.8466\n",
            "Epoch [99/100], Loss: 0.2774\n",
            "Epoch [99/100], Time: 28.6096\n",
            "Validation loss: 0.0079, Validation accuracy: 0.8207\n",
            "Epoch [100/100], Loss: 0.2645\n",
            "Epoch [100/100], Time: 28.8078\n",
            "Validation loss: 0.0183, Validation accuracy: 0.8396\n",
            "==================================================\n",
            "==> Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/ece661/final_project/saved_model_rotnet/rotnet_epoch_99.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh0Cl7bgSxhz",
        "outputId": "a2dd49ce-a60b-4406-9515-562fcd16b1eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6 Linear Evaluation"
      ],
      "metadata": {
        "id": "OXFxBHl7Sh5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.projection_head = nn.Linear(512, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "for param in model.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "fFRQvx53SpFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"./data\"\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "transform_classify = transforms.Compose(\n",
        "                            [transforms.ToTensor(),\n",
        "                             transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "\n",
        "\n",
        "tra_set = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform_classify)\n",
        "val_set = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform_classify)\n",
        "\n",
        "normal_train_loader = DataLoader(\n",
        "    tra_set,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "normal_validate_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhes3Z2OSqWi",
        "outputId": "1d87e6b0-00e8-4fe1-a365-6f1782905721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "print(\"==> Training starts!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Learning rate decay setup\n",
        "INITIAL_LR = 0.001\n",
        "MOMENTUM = 0.09\n",
        "REG = 1e-4\n",
        "\n",
        "DECAY_EPOCHS = 8\n",
        "DECAY = 0.75\n",
        "current_learning_rate = INITIAL_LR\n",
        "EPOCHS = 23\n",
        "CHECKPOINT_FOLDER = \"/content/drive/My Drive/ece661/final_project/saved_model\"\n",
        "\n",
        "# Training loop\n",
        "start_time = time.time()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n",
        "for epoch in range(0, EPOCHS):\n",
        "\n",
        "    if epoch % DECAY_EPOCHS == 0 and epoch != 0:\n",
        "        current_learning_rate *= DECAY\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = current_learning_rate\n",
        "        print(\"Current learning rate has decayed to %f\" % current_learning_rate)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (image, label) in enumerate(normal_train_loader):\n",
        "\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # compute the output and loss\n",
        "        output = model.forward(image)\n",
        "        loss = criterion(output, label)\n",
        "        train_loss = loss.detach()\n",
        "\n",
        "        # zero the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # apply gradient and update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += train_loss\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(normal_train_loader)\n",
        "    print(\"Epoch [%d/%d], Loss: %.4f\" % (epoch + 1, EPOCHS, avg_loss))\n",
        "    end_time = time.time()\n",
        "    print(\"Epoch [%d/%d], Time: %.4f\" % (epoch + 1, EPOCHS, end_time-start_time))\n",
        "    start_time = end_time\n",
        "\n",
        "    model.eval()\n",
        "    correct_examples = 0\n",
        "    total_examples = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(normal_validate_loader):\n",
        "            ####################################\n",
        "            # your code here\n",
        "            # copy inputs to device\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute the output and loss\n",
        "            output = model.forward(inputs)\n",
        "            loss = criterion(output, targets)\n",
        "            val_loss = loss.detach()\n",
        "\n",
        "            # count the number of correctly predicted samples in the current batch\n",
        "            _, predicted_results = torch.max(output, 1)\n",
        "            correct_predictions = (predicted_results == targets)\n",
        "            correct_examples += correct_predictions.sum().item()\n",
        "            total_examples += len(targets)\n",
        "            ####################################\n",
        "\n",
        "    avg_loss = val_loss / len(normal_validate_loader)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"==> Training complete\")\n",
        "\n",
        "# Save checkpoint\n",
        "if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "    os.makedirs(CHECKPOINT_FOLDER)\n",
        "torch.save(model.state_dict(), os.path.join(CHECKPOINT_FOLDER, 'rotnet_linear_eval.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evc3VRT4S6nR",
        "outputId": "6970d3ee-2cae-41a0-8c6a-cb3ef2c05cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch [1/23], Loss: 1.5796\n",
            "Epoch [1/23], Time: 4.9916\n",
            "Validation loss: 0.0451, Validation accuracy: 0.4756\n",
            "Epoch [2/23], Loss: 1.5762\n",
            "Epoch [2/23], Time: 5.9922\n",
            "Validation loss: 0.0427, Validation accuracy: 0.4740\n",
            "Epoch [3/23], Loss: 1.5708\n",
            "Epoch [3/23], Time: 6.1978\n",
            "Validation loss: 0.0406, Validation accuracy: 0.4756\n",
            "Epoch [4/23], Loss: 1.5699\n",
            "Epoch [4/23], Time: 6.0361\n",
            "Validation loss: 0.0389, Validation accuracy: 0.4733\n",
            "Epoch [5/23], Loss: 1.5725\n",
            "Epoch [5/23], Time: 6.0276\n",
            "Validation loss: 0.0443, Validation accuracy: 0.4727\n",
            "Epoch [6/23], Loss: 1.5722\n",
            "Epoch [6/23], Time: 6.0397\n",
            "Validation loss: 0.0320, Validation accuracy: 0.4716\n",
            "Epoch [7/23], Loss: 1.5712\n",
            "Epoch [7/23], Time: 6.2754\n",
            "Validation loss: 0.0339, Validation accuracy: 0.4757\n",
            "Epoch [8/23], Loss: 1.5690\n",
            "Epoch [8/23], Time: 6.1549\n",
            "Validation loss: 0.0383, Validation accuracy: 0.4751\n",
            "Current learning rate has decayed to 0.000750\n",
            "Epoch [9/23], Loss: 1.5694\n",
            "Epoch [9/23], Time: 6.3158\n",
            "Validation loss: 0.0477, Validation accuracy: 0.4720\n",
            "Epoch [10/23], Loss: 1.5710\n",
            "Epoch [10/23], Time: 6.2335\n",
            "Validation loss: 0.0564, Validation accuracy: 0.4735\n",
            "Epoch [11/23], Loss: 1.5687\n",
            "Epoch [11/23], Time: 5.9973\n",
            "Validation loss: 0.0405, Validation accuracy: 0.4746\n",
            "Epoch [12/23], Loss: 1.5665\n",
            "Epoch [12/23], Time: 6.2877\n",
            "Validation loss: 0.0492, Validation accuracy: 0.4759\n",
            "Epoch [13/23], Loss: 1.5655\n",
            "Epoch [13/23], Time: 6.0804\n",
            "Validation loss: 0.0505, Validation accuracy: 0.4750\n",
            "Epoch [14/23], Loss: 1.5672\n",
            "Epoch [14/23], Time: 6.1854\n",
            "Validation loss: 0.0562, Validation accuracy: 0.4707\n",
            "Epoch [15/23], Loss: 1.5682\n",
            "Epoch [15/23], Time: 5.9893\n",
            "Validation loss: 0.0395, Validation accuracy: 0.4753\n",
            "Epoch [16/23], Loss: 1.5703\n",
            "Epoch [16/23], Time: 6.4276\n",
            "Validation loss: 0.0461, Validation accuracy: 0.4730\n",
            "Current learning rate has decayed to 0.000563\n",
            "Epoch [17/23], Loss: 1.5656\n",
            "Epoch [17/23], Time: 6.0248\n",
            "Validation loss: 0.0390, Validation accuracy: 0.4734\n",
            "Epoch [18/23], Loss: 1.5677\n",
            "Epoch [18/23], Time: 6.1081\n",
            "Validation loss: 0.0689, Validation accuracy: 0.4757\n",
            "Epoch [19/23], Loss: 1.5661\n",
            "Epoch [19/23], Time: 6.0782\n",
            "Validation loss: 0.0382, Validation accuracy: 0.4735\n",
            "Epoch [20/23], Loss: 1.5665\n",
            "Epoch [20/23], Time: 6.1669\n",
            "Validation loss: 0.0465, Validation accuracy: 0.4735\n",
            "Epoch [21/23], Loss: 1.5681\n",
            "Epoch [21/23], Time: 6.1427\n",
            "Validation loss: 0.0402, Validation accuracy: 0.4742\n",
            "Epoch [22/23], Loss: 1.5668\n",
            "Epoch [22/23], Time: 6.0710\n",
            "Validation loss: 0.0366, Validation accuracy: 0.4746\n",
            "Epoch [23/23], Loss: 1.5658\n",
            "Epoch [23/23], Time: 6.1699\n",
            "Validation loss: 0.0756, Validation accuracy: 0.4730\n",
            "==================================================\n",
            "==> Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Classifier Finetune"
      ],
      "metadata": {
        "id": "xAHs9iAE6GGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/ece661/final_project/saved_model_rotnet/rotnet_epoch_99.pth'))"
      ],
      "metadata": {
        "id": "ubxfDe1tyQrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7635d33f-49bb-4e3c-fee4-868b823ca8cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the new classifier as a separate module\n",
        "class RotNetClassifier(nn.Module):\n",
        "    def __init__(self, input_features=512, features=200, num_classes=10):\n",
        "        super(RotNetClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_features, features)\n",
        "        self.bn1 = nn.BatchNorm1d(features)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(features, features)\n",
        "        self.bn2 = nn.BatchNorm1d(features)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.fc3 = nn.Linear(features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7jOV3ozx56vD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "classifier = RotNetClassifier()\n",
        "\n",
        "model.projection_head = classifier\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ADDjR-1J2Z4y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY_EUc1O69nO",
        "outputId": "57f36123-1517-4782-e2df-878d2f288579"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RotNet(\n",
              "  (encoder): ResNetEncoder(\n",
              "    (base_model): ResNet(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (fc): Identity()\n",
              "    )\n",
              "  )\n",
              "  (projection_head): RotNetClassifier(\n",
              "    (fc1): Linear(in_features=512, out_features=200, bias=True)\n",
              "    (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU()\n",
              "    (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
              "    (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU()\n",
              "    (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"./data\"\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "transform_classify = transforms.Compose(\n",
        "                            [transforms.ToTensor(),\n",
        "                             transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "\n",
        "\n",
        "tra_set = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform_classify)\n",
        "val_set = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform_classify)\n",
        "\n",
        "\n",
        "classifier_raw_set_50000 = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform_classify)\n",
        "\n",
        "size = 5000\n",
        "\n",
        "indices = torch.randperm(len(classifier_raw_set_50000))[:size].tolist()\n",
        "subset = torch.utils.data.Subset(classifier_raw_set_50000, indices)\n",
        "\n",
        "\n",
        "normal_train_loader = DataLoader(\n",
        "    subset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "normal_validate_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n"
      ],
      "metadata": {
        "id": "dm_4sYjk2pOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9548968a-c792-48c8-aacd-d76f4c50660c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "print(\"==> Training starts!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Learning rate decay setup\n",
        "INITIAL_LR = 0.5\n",
        "MOMENTUM = 0.9\n",
        "REG = 1e-4\n",
        "\n",
        "DECAY_EPOCHS = 8\n",
        "DECAY = 0.75\n",
        "current_learning_rate = INITIAL_LR\n",
        "EPOCHS = 20\n",
        "CHECKPOINT_FOLDER = \"/content/drive/My Drive/ece661/final_project/saved_model\"\n",
        "\n",
        "# Training loop\n",
        "start_time = time.time()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n",
        "for epoch in range(0, EPOCHS):\n",
        "\n",
        "    if epoch % DECAY_EPOCHS == 0 and epoch != 0:\n",
        "        current_learning_rate *= DECAY\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = current_learning_rate\n",
        "        print(\"Current learning rate has decayed to %f\" % current_learning_rate)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (image, label) in enumerate(normal_train_loader):\n",
        "\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # compute the output and loss\n",
        "        output = model.forward(image)\n",
        "        loss = criterion(output, label)\n",
        "        train_loss = loss.detach()\n",
        "\n",
        "        # zero the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # apply gradient and update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += train_loss\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(normal_train_loader)\n",
        "    print(\"Epoch [%d/%d], Loss: %.4f\" % (epoch + 1, EPOCHS, avg_loss))\n",
        "    end_time = time.time()\n",
        "    print(\"Epoch [%d/%d], Time: %.4f\" % (epoch + 1, EPOCHS, end_time-start_time))\n",
        "    start_time = end_time\n",
        "\n",
        "    model.eval()\n",
        "    correct_examples = 0\n",
        "    total_examples = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(normal_validate_loader):\n",
        "            ####################################\n",
        "            # your code here\n",
        "            # copy inputs to device\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute the output and loss\n",
        "            output = model.forward(inputs)\n",
        "            loss = criterion(output, targets)\n",
        "            val_loss = loss.detach()\n",
        "\n",
        "            # count the number of correctly predicted samples in the current batch\n",
        "            _, predicted_results = torch.max(output, 1)\n",
        "            correct_predictions = (predicted_results == targets)\n",
        "            correct_examples += correct_predictions.sum().item()\n",
        "            total_examples += len(targets)\n",
        "            ####################################\n",
        "\n",
        "    avg_loss = val_loss / len(normal_validate_loader)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"==> Training complete\")\n",
        "\n",
        "# Save checkpoint\n",
        "if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "    os.makedirs(CHECKPOINT_FOLDER)\n",
        "torch.save(model.state_dict(), os.path.join(CHECKPOINT_FOLDER, 'ROTNET_with_decoder_size_%d.pth' % size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSK5rJN22m9O",
        "outputId": "e0fe0bfc-1df4-400e-ef03-9bfcd595ccfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch [1/20], Loss: 0.1508\n",
            "Epoch [1/20], Time: 1.8194\n",
            "Validation loss: 0.0908, Validation accuracy: 0.7498\n",
            "Epoch [2/20], Loss: 0.0766\n",
            "Epoch [2/20], Time: 3.3094\n",
            "Validation loss: 0.1370, Validation accuracy: 0.5887\n",
            "Epoch [3/20], Loss: 1.6997\n",
            "Epoch [3/20], Time: 3.2417\n",
            "Validation loss: 2.2714, Validation accuracy: 0.1011\n",
            "Epoch [4/20], Loss: 1.1509\n",
            "Epoch [4/20], Time: 3.1981\n",
            "Validation loss: 0.1163, Validation accuracy: 0.4768\n",
            "Epoch [5/20], Loss: 0.6596\n",
            "Epoch [5/20], Time: 3.2477\n",
            "Validation loss: 0.0365, Validation accuracy: 0.6121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation loss: 0.0073, Validation accuracy: 0.7585 for 5000\n",
        "\n",
        "Validation loss: 0.0027, Validation accuracy: 0.7719\n",
        "for 7500\n",
        "> 缩进块\n",
        "\n"
      ],
      "metadata": {
        "id": "9hhusx2n0kN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "eBe2QjdQ5HHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Z99cT8VAhqz8",
        "OXFxBHl7Sh5J"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}